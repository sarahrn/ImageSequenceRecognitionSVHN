{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle\n",
    "from six.moves import range\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n",
      "Int64Index([    1,     2,     3,     4,     5,     6,     7,     8,     9,\n",
      "               10,\n",
      "            ...\n",
      "            33393, 33394, 33395, 33396, 33397, 33398, 33399, 33400, 33401,\n",
      "            33402],\n",
      "           dtype='int64', name=u'ImageNumber', length=33373)\n",
      "(33373, 55)\n"
     ]
    }
   ],
   "source": [
    "pickle_file = 'SVHN.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  train_dataset = save['train_dataset']\n",
    "  train_labels = save['train_labels']\n",
    "  #valid_dataset = save['valid_dataset']\n",
    "  #valid_labels = save['valid_labels']\n",
    "  test_dataset = save['test_dataset']\n",
    "  test_labels = save['test_labels']\n",
    "  del save  # hint to help gc free up memory\n",
    "  #print('Training set', train_dataset.shape, train_labels.shape)\n",
    "  print(type(train_dataset))\n",
    "  print(train_labels.index)\n",
    "  print(train_labels.shape)\n",
    "    \n",
    "  train_image_labels = train_labels.index\n",
    "  test_image_labels = test_labels.index\n",
    "  #print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "  #print('Test set', test_dataset.shape, test_labels.shape)\n",
    "\n",
    "train_labels = train_labels.values\n",
    "test_labels = test_labels.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.06862745,  0.07254902,  0.08431373],\n",
       "         [ 0.04509804,  0.06078431,  0.06862745],\n",
       "         [ 0.02156863,  0.04117647,  0.04509804],\n",
       "         ..., \n",
       "         [-0.02941176, -0.0254902 , -0.01764706],\n",
       "         [ 0.13529412,  0.14313726,  0.14313726],\n",
       "         [ 0.28431374,  0.28431374,  0.28823531]],\n",
       "\n",
       "        [[ 0.04901961,  0.06078431,  0.08039216],\n",
       "         [ 0.03333334,  0.04901961,  0.06078431],\n",
       "         [ 0.00980392,  0.02941176,  0.02941176],\n",
       "         ..., \n",
       "         [-0.0254902 , -0.02156863, -0.00980392],\n",
       "         [ 0.11960784,  0.12352941,  0.13137256],\n",
       "         [ 0.26862746,  0.26862746,  0.28039217]],\n",
       "\n",
       "        [[ 0.03333334,  0.04117647,  0.06470589],\n",
       "         [ 0.01764706,  0.02941176,  0.04117647],\n",
       "         [-0.00588235,  0.00980392,  0.01372549],\n",
       "         ..., \n",
       "         [-0.02156863, -0.01372549,  0.00196078],\n",
       "         [ 0.06470589,  0.06862745,  0.07647059],\n",
       "         [ 0.17843138,  0.18235295,  0.19019608]],\n",
       "\n",
       "        ..., \n",
       "        [[ 0.36666667,  0.37843138,  0.38627452],\n",
       "         [ 0.36666667,  0.37450981,  0.38627452],\n",
       "         [ 0.38627452,  0.39411765,  0.40588236],\n",
       "         ..., \n",
       "         [ 0.47254902,  0.47254902,  0.47647059],\n",
       "         [ 0.48823529,  0.5       ,  0.49607843],\n",
       "         [ 0.45294118,  0.46470588,  0.48823529]],\n",
       "\n",
       "        [[ 0.37058824,  0.37450981,  0.38235295],\n",
       "         [ 0.36666667,  0.37058824,  0.37843138],\n",
       "         [ 0.39019608,  0.39411765,  0.40196079],\n",
       "         ..., \n",
       "         [ 0.46862745,  0.47254902,  0.46470588],\n",
       "         [ 0.48039216,  0.49215686,  0.48431373],\n",
       "         [ 0.46470588,  0.48039216,  0.49607843]],\n",
       "\n",
       "        [[ 0.36666667,  0.37058824,  0.37843138],\n",
       "         [ 0.36666667,  0.37058824,  0.37843138],\n",
       "         [ 0.38627452,  0.39019608,  0.39803922],\n",
       "         ..., \n",
       "         [ 0.47254902,  0.47647059,  0.46078432],\n",
       "         [ 0.48039216,  0.49215686,  0.47647059],\n",
       "         [ 0.46470588,  0.48039216,  0.49215686]]],\n",
       "\n",
       "\n",
       "       [[[ 0.18235295,  0.17843138,  0.13529412],\n",
       "         [ 0.16666667,  0.1627451 ,  0.12352941],\n",
       "         [ 0.15490197,  0.15490197,  0.11568628],\n",
       "         ..., \n",
       "         [-0.04509804, -0.00588235, -0.00980392],\n",
       "         [-0.18627451, -0.14313726, -0.13137256],\n",
       "         [-0.28823531, -0.24117647, -0.20980392]],\n",
       "\n",
       "        [[ 0.18627451,  0.17450981,  0.13921569],\n",
       "         [ 0.17058824,  0.1627451 ,  0.12745099],\n",
       "         [ 0.15490197,  0.15490197,  0.11960784],\n",
       "         ..., \n",
       "         [-0.06470589, -0.02941176, -0.0372549 ],\n",
       "         [-0.20588236, -0.1627451 , -0.15490197],\n",
       "         [-0.29607844, -0.25294119, -0.2254902 ]],\n",
       "\n",
       "        [[ 0.18627451,  0.17450981,  0.13921569],\n",
       "         [ 0.17058824,  0.1627451 ,  0.13137256],\n",
       "         [ 0.1509804 ,  0.1509804 ,  0.11960784],\n",
       "         ..., \n",
       "         [-0.0882353 , -0.05294118, -0.06078431],\n",
       "         [-0.2254902 , -0.18627451, -0.17450981],\n",
       "         [-0.30784315, -0.2647059 , -0.24117647]],\n",
       "\n",
       "        ..., \n",
       "        [[ 0.17450981,  0.17450981,  0.15490197],\n",
       "         [ 0.14705883,  0.14313726,  0.13921569],\n",
       "         [ 0.12745099,  0.12352941,  0.12745099],\n",
       "         ..., \n",
       "         [-0.0254902 , -0.0372549 , -0.07647059],\n",
       "         [-0.08431373, -0.0882353 , -0.10784314],\n",
       "         [-0.13921569, -0.13921569, -0.14705883]],\n",
       "\n",
       "        [[ 0.17450981,  0.16666667,  0.15882353],\n",
       "         [ 0.14705883,  0.13921569,  0.14313726],\n",
       "         [ 0.12745099,  0.11960784,  0.13137256],\n",
       "         ..., \n",
       "         [-0.02941176, -0.04117647, -0.06862745],\n",
       "         [-0.09215686, -0.09607843, -0.11176471],\n",
       "         [-0.14705883, -0.14705883, -0.15490197]],\n",
       "\n",
       "        [[ 0.17450981,  0.17058824,  0.1627451 ],\n",
       "         [ 0.14705883,  0.13921569,  0.1509804 ],\n",
       "         [ 0.12352941,  0.11568628,  0.13137256],\n",
       "         ..., \n",
       "         [-0.04117647, -0.04509804, -0.06470589],\n",
       "         [-0.09607843, -0.09607843, -0.11176471],\n",
       "         [-0.14705883, -0.14705883, -0.1509804 ]]],\n",
       "\n",
       "\n",
       "       [[[-0.1       , -0.08039216, -0.08039216],\n",
       "         [-0.1       , -0.08039216, -0.07254902],\n",
       "         [-0.09607843, -0.08431373, -0.06470589],\n",
       "         ..., \n",
       "         [-0.13529412, -0.09607843, -0.0882353 ],\n",
       "         [-0.1509804 , -0.11568628, -0.09607843],\n",
       "         [-0.15490197, -0.12352941, -0.09607843]],\n",
       "\n",
       "        [[-0.09607843, -0.07647059, -0.06470589],\n",
       "         [-0.09607843, -0.08039216, -0.06862745],\n",
       "         [-0.1       , -0.0882353 , -0.07254902],\n",
       "         ..., \n",
       "         [-0.13921569, -0.10392157, -0.09607843],\n",
       "         [-0.1509804 , -0.11960784, -0.1       ],\n",
       "         [-0.15490197, -0.12745099, -0.1       ]],\n",
       "\n",
       "        [[-0.09607843, -0.07647059, -0.06470589],\n",
       "         [-0.1       , -0.08039216, -0.06862745],\n",
       "         [-0.10392157, -0.09215686, -0.08039216],\n",
       "         ..., \n",
       "         [-0.13921569, -0.11176471, -0.10784314],\n",
       "         [-0.14705883, -0.11960784, -0.1       ],\n",
       "         [-0.14705883, -0.11960784, -0.09607843]],\n",
       "\n",
       "        ..., \n",
       "        [[-0.12745099, -0.1       , -0.0882353 ],\n",
       "         [-0.13529412, -0.10392157, -0.09215686],\n",
       "         [-0.12745099, -0.09607843, -0.0882353 ],\n",
       "         ..., \n",
       "         [-0.1509804 , -0.11568628, -0.08431373],\n",
       "         [-0.15490197, -0.11568628, -0.09607843],\n",
       "         [-0.15882353, -0.11568628, -0.10392157]],\n",
       "\n",
       "        [[-0.13137256, -0.1       , -0.0882353 ],\n",
       "         [-0.13529412, -0.10392157, -0.09215686],\n",
       "         [-0.12745099, -0.09607843, -0.08431373],\n",
       "         ..., \n",
       "         [-0.14705883, -0.11176471, -0.09215686],\n",
       "         [-0.15490197, -0.11960784, -0.1       ],\n",
       "         [-0.15882353, -0.11568628, -0.1       ]],\n",
       "\n",
       "        [[-0.13137256, -0.1       , -0.0882353 ],\n",
       "         [-0.13529412, -0.10392157, -0.09215686],\n",
       "         [-0.13137256, -0.1       , -0.0882353 ],\n",
       "         ..., \n",
       "         [-0.14705883, -0.11176471, -0.09215686],\n",
       "         [-0.1509804 , -0.11568628, -0.09607843],\n",
       "         [-0.15882353, -0.11568628, -0.1       ]]],\n",
       "\n",
       "\n",
       "       [[[-0.35490197, -0.34705883, -0.28823531],\n",
       "         [-0.34705883, -0.34705883, -0.2764706 ],\n",
       "         [-0.36274511, -0.35490197, -0.2764706 ],\n",
       "         ..., \n",
       "         [-0.31176472, -0.31568629, -0.28431374],\n",
       "         [-0.33137256, -0.3392157 , -0.29607844],\n",
       "         [-0.34705883, -0.35490197, -0.31176472]],\n",
       "\n",
       "        [[-0.40980393, -0.40588236, -0.33529413],\n",
       "         [-0.39803922, -0.39411765, -0.31568629],\n",
       "         [-0.41764706, -0.40588236, -0.33137256],\n",
       "         ..., \n",
       "         [-0.32352942, -0.33529413, -0.30000001],\n",
       "         [-0.35882354, -0.36666667, -0.32745099],\n",
       "         [-0.38627452, -0.38627452, -0.3392157 ]],\n",
       "\n",
       "        [[-0.42156863, -0.40980393, -0.34313726],\n",
       "         [-0.40980393, -0.39803922, -0.32352942],\n",
       "         [-0.4254902 , -0.40588236, -0.32745099],\n",
       "         ..., \n",
       "         [-0.29607844, -0.30784315, -0.27254903],\n",
       "         [-0.3509804 , -0.35882354, -0.31568629],\n",
       "         [-0.39019608, -0.39019608, -0.34313726]],\n",
       "\n",
       "        ..., \n",
       "        [[-0.42156863, -0.4254902 , -0.35490197],\n",
       "         [-0.42156863, -0.41764706, -0.33529413],\n",
       "         [-0.42941177, -0.40588236, -0.33137256],\n",
       "         ..., \n",
       "         [-0.34705883, -0.31568629, -0.28039217],\n",
       "         [-0.39019608, -0.35882354, -0.31568629],\n",
       "         [-0.42941177, -0.39019608, -0.34313726]],\n",
       "\n",
       "        [[-0.41764706, -0.42156863, -0.35882354],\n",
       "         [-0.41764706, -0.4137255 , -0.33529413],\n",
       "         [-0.43333334, -0.4137255 , -0.3392157 ],\n",
       "         ..., \n",
       "         [-0.39803922, -0.36274511, -0.32745099],\n",
       "         [-0.42156863, -0.38235295, -0.34313726],\n",
       "         [-0.44117647, -0.40196079, -0.35490197]],\n",
       "\n",
       "        [[-0.4137255 , -0.41764706, -0.36274511],\n",
       "         [-0.41764706, -0.40980393, -0.3509804 ],\n",
       "         [-0.42156863, -0.40980393, -0.34313726],\n",
       "         ..., \n",
       "         [-0.43725491, -0.39803922, -0.36274511],\n",
       "         [-0.44117647, -0.40196079, -0.36274511],\n",
       "         [-0.44901961, -0.40980393, -0.36274511]]],\n",
       "\n",
       "\n",
       "       [[[-0.28039217, -0.2372549 , -0.25294119],\n",
       "         [-0.28039217, -0.24509804, -0.24901961],\n",
       "         [-0.27254903, -0.24901961, -0.24901961],\n",
       "         ..., \n",
       "         [-0.27254903, -0.23333333, -0.19411765],\n",
       "         [-0.28431374, -0.24901961, -0.19019608],\n",
       "         [-0.28823531, -0.25294119, -0.18627451]],\n",
       "\n",
       "        [[-0.28823531, -0.24117647, -0.24901961],\n",
       "         [-0.28823531, -0.24901961, -0.24509804],\n",
       "         [-0.28431374, -0.25294119, -0.24509804],\n",
       "         ..., \n",
       "         [-0.2764706 , -0.24509804, -0.20196079],\n",
       "         [-0.26862746, -0.2372549 , -0.18627451],\n",
       "         [-0.28823531, -0.25294119, -0.19411765]],\n",
       "\n",
       "        [[-0.29215688, -0.24509804, -0.24509804],\n",
       "         [-0.28823531, -0.24901961, -0.24117647],\n",
       "         [-0.28823531, -0.25686276, -0.24509804],\n",
       "         ..., \n",
       "         [-0.2764706 , -0.25294119, -0.19803922],\n",
       "         [-0.26862746, -0.24509804, -0.19803922],\n",
       "         [-0.28823531, -0.25686276, -0.21372549]],\n",
       "\n",
       "        ..., \n",
       "        [[-0.30784315, -0.2254902 , -0.25294119],\n",
       "         [-0.30784315, -0.22941177, -0.2372549 ],\n",
       "         [-0.30392158, -0.2254902 , -0.22941177],\n",
       "         ..., \n",
       "         [-0.28823531, -0.30000001, -0.23333333],\n",
       "         [-0.29215688, -0.29607844, -0.2254902 ],\n",
       "         [-0.29215688, -0.28823531, -0.21764706]],\n",
       "\n",
       "        [[-0.28823531, -0.22941177, -0.24117647],\n",
       "         [-0.28039217, -0.2254902 , -0.2254902 ],\n",
       "         [-0.28039217, -0.2254902 , -0.21372549],\n",
       "         ..., \n",
       "         [-0.28823531, -0.28039217, -0.23333333],\n",
       "         [-0.29607844, -0.28823531, -0.2372549 ],\n",
       "         [-0.29215688, -0.28039217, -0.22156863]],\n",
       "\n",
       "        [[-0.27254903, -0.24117647, -0.22941177],\n",
       "         [-0.25294119, -0.24117647, -0.21372549],\n",
       "         [-0.24509804, -0.24509804, -0.19803922],\n",
       "         ..., \n",
       "         [-0.28431374, -0.2647059 , -0.24117647],\n",
       "         [-0.28823531, -0.27254903, -0.2372549 ],\n",
       "         [-0.30000001, -0.27254903, -0.24117647]]]], dtype=float32)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def six_labels_to_five(test_labels):    \n",
    "    test_labels_sample_orig = pd.DataFrame(test_labels).copy()\n",
    "    num_lab_orig = pd.DataFrame(test_labels).ix[:,50:54].copy()\n",
    "    num_lab_new = num_lab_orig.copy()\n",
    "    num_lab_new[num_lab_new==0] = np.nan\n",
    "    num_lab_new = num_lab_new.T\n",
    "    num_lab_new = num_lab_new.fillna(method='bfill')\n",
    "    num_lab_new = num_lab_new.T\n",
    "    num_lab_new[num_lab_new==1] = 0\n",
    "    num_lab_new = num_lab_new.fillna(1)\n",
    "    test_labels_sample_orig.ix[:,50:54] = num_lab_new\n",
    "    cols = test_labels_sample_orig.columns.tolist()\n",
    "    cols = cols[:10] + cols[50:51] + cols[10:20] + cols[51:52] + cols[20:30] + cols[52:53] + cols[30:40] + cols[53:54] + cols[40:50] + cols[54:55]\n",
    "    test_labels_sample_orig = test_labels_sample_orig.fillna(0)\n",
    "    test_labels_sample_new = test_labels_sample_orig[cols]\n",
    "    return test_labels_sample_new\n",
    "\n",
    "test_labels = six_labels_to_five(test_labels)\n",
    "train_labels = six_labels_to_five(train_labels)\n",
    "\n",
    "#print(test_labels[1:2])\n",
    "#print(six_labels_to_five(test_labels)[1:2].values.reshape(5,11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "merged_dataset = np.concatenate((train_dataset,test_dataset))\n",
    "merged_labels = np.concatenate((train_labels,test_labels))\n",
    "merged_image_labels = np.concatenate((train_image_labels,test_image_labels))\n",
    "\n",
    "def randomize(dataset, labels, image_labels):\n",
    "  permutation = np.random.permutation(labels.shape[0])\n",
    "  shuffled_dataset = dataset[permutation,:,:]\n",
    "  shuffled_labels = labels[permutation]\n",
    "  shuffled_image_labels = image_labels[permutation]\n",
    "  return shuffled_dataset, shuffled_labels, shuffled_image_labels\n",
    "merged_dataset, merged_labels, merged_image_labels = randomize(merged_dataset, merged_labels, merged_image_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.int64'>\n",
      "test/cropped/28620.png\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAJPUlEQVRIDQ3BaW9j53UA4HPe5a4k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\nzvqmts7R/wFpgMhWZ5UPlwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.]], dtype=float32)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Test a sample image to make sure \n",
    "\n",
    "from IPython.display import display, Image\n",
    "print(type(merged_image_labels[1]))\n",
    "print(\"test/cropped/\" + str(merged_image_labels[1]) + \".png\")\n",
    "display(Image(filename=\"train/cropped/\" + str(merged_image_labels[5]) + \".png\"))\n",
    "merged_labels[5].reshape(5,11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_dataset = merged_dataset[0:merged_dataset.shape[0]/2,]\n",
    "valid_dataset = merged_dataset[(merged_dataset.shape[0]/2):\n",
    "                                    (merged_dataset.shape[0]/2+merged_dataset.shape[0]/4),]\n",
    "test_dataset = merged_dataset[(merged_dataset.shape[0]/2+merged_dataset.shape[0]/4):merged_dataset.shape[0],]\n",
    "\n",
    "train_labels = merged_labels[0:merged_labels.shape[0]/2,]\n",
    "valid_labels = merged_labels[(merged_labels.shape[0]/2):\n",
    "                                    (merged_labels.shape[0]/2+merged_labels.shape[0]/4),]\n",
    "test_labels = merged_labels[(merged_labels.shape[0]/2+merged_labels.shape[0]/4):merged_labels.shape[0],]\n",
    "\n",
    "train_image_labels = merged_image_labels[0:merged_image_labels.shape[0]/2,]\n",
    "valid_image_labels = merged_image_labels[(merged_image_labels.shape[0]/2):\n",
    "                                    (merged_image_labels.shape[0]/2+merged_image_labels.shape[0]/4),]\n",
    "test_image_labels = merged_image_labels[(merged_image_labels.shape[0]/2+merged_image_labels.shape[0]/4):merged_image_labels.shape[0],]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2177\n",
      "[[ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      " [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAK+0lEQVRIDQXBV4yj+UEA8P//683l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\nbe0m2WezAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.]\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.]\n"
     ]
    }
   ],
   "source": [
    "print(train_image_labels[0])\n",
    "print(train_labels[0].reshape(5,11))\n",
    "display(Image(filename=\"test/cropped/\" + str(train_image_labels[0]) + \".png\"))\n",
    "\n",
    "train_labels_1 = train_labels[:,0:11]\n",
    "train_labels_2 = train_labels[:,11:22]\n",
    "train_labels_3 = train_labels[:,22:33]\n",
    "train_labels_4 = train_labels[:,33:44]\n",
    "train_labels_5 = train_labels[:,44:55]\n",
    "\n",
    "print(train_labels_1[0])\n",
    "print(train_labels_2[0])\n",
    "print(train_labels_3[0])\n",
    "print(train_labels_4[0])\n",
    "print(train_labels_5[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_labels_1 = train_labels[:,0:11]\n",
    "train_labels_2 = train_labels[:,11:22]\n",
    "train_labels_3 = train_labels[:,22:33]\n",
    "train_labels_4 = train_labels[:,33:44]\n",
    "train_labels_5 = train_labels[:,44:55]\n",
    "#train_labels_6 = train_labels[:,50:55]\n",
    "\n",
    "valid_labels_1 = valid_labels[:,0:11]\n",
    "valid_labels_2 = valid_labels[:,11:22]\n",
    "valid_labels_3 = valid_labels[:,22:33]\n",
    "valid_labels_4 = valid_labels[:,33:44]\n",
    "valid_labels_5 = valid_labels[:,44:55]\n",
    "#valid_labels_6 = valid_labels[:,50:55]\n",
    "\n",
    "test_labels_1 = test_labels[:,0:11]\n",
    "test_labels_2 = test_labels[:,11:22]\n",
    "test_labels_3 = test_labels[:,22:33]\n",
    "test_labels_4 = test_labels[:,33:44]\n",
    "test_labels_5 = test_labels[:,44:55]\n",
    "#test_labels_6 = test_labels[:,50:55]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "  labels_1 = labels[:,0:11]\n",
    "  labels_2 = labels[:,11:22]\n",
    "  labels_3 = labels[:,22:33]\n",
    "  labels_4 = labels[:,33:44]\n",
    "  labels_5 = labels[:,44:55]\n",
    "\n",
    "  predictions_1 = predictions[:,0:11]\n",
    "  predictions_2 = predictions[:,11:22]\n",
    "  predictions_3 = predictions[:,22:33]\n",
    "  predictions_4 = predictions[:,33:44]\n",
    "  predictions_5 = predictions[:,44:55]\n",
    "    \n",
    "  total_observations = predictions.shape[0]\n",
    "  #print(predictions[:,:11])\n",
    "  acc_1 = np.argmax(predictions_1, 1) == np.argmax(labels_1, 1)\n",
    "  acc_2 = np.argmax(predictions_2, 1) == np.argmax(labels_2, 1)\n",
    "  acc_3 = np.argmax(predictions_3, 1) == np.argmax(labels_3, 1)\n",
    "  acc_4 = np.argmax(predictions_4, 1) == np.argmax(labels_4, 1)\n",
    "  acc_5 = np.argmax(predictions_5, 1) == np.argmax(labels_5, 1)\n",
    "\n",
    "  acc = acc_1 & acc_2 & acc_3 & acc_4 & acc_5\n",
    "  \n",
    "  print(predictions_1[0])\n",
    "  print(labels_1[0])\n",
    "  print(\"Predicted: \" + str(np.argmax(predictions_1[0])) + \" \" + str(np.argmax(predictions_2[0]))  + \" \" + \n",
    "        str(np.argmax(predictions_3[0]))  + \" \" + str(np.argmax(predictions_4[0]))  + \" \" + str(np.argmax(predictions_5[0])))\n",
    "  print(\"Actual: \" + str(np.argmax(labels_1[0])) + \" \" + str(np.argmax(labels_2[0]))  + \" \" + \n",
    "        str(np.argmax(labels_3[0]))  + \" \" + str(np.argmax(labels_4[0]))  + \" \" + str(np.argmax(labels_5[0])))\n",
    "\n",
    "  return (100.0 * np.sum(acc)\n",
    "          / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11608, 32, 32, 3)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"add_3:0\", shape=(100, 11), dtype=float32)\n",
      "Tensor(\"Placeholder_1:0\", shape=(100, 11), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "patch_size = 5\n",
    "depth = 16\n",
    "num_hidden = 64\n",
    "image_size = 32\n",
    "num_channels = 3\n",
    "num_labels = 11\n",
    "num_numbers = 5\n",
    "\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  tf_train_dataset = tf.placeholder(\n",
    "    tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "    \n",
    "  tf_train_labels1 = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_train_labels2 = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_train_labels3 = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_train_labels4 = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_train_labels5 = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "    \n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "    \n",
    "  \n",
    "  # Variables.\n",
    "  layer1_weights = tf.Variable(tf.truncated_normal(\n",
    "      [patch_size, patch_size, num_channels, depth], stddev=0.1))\n",
    "  layer1_biases = tf.Variable(tf.zeros([depth]))\n",
    "  layer2_weights = tf.Variable(tf.truncated_normal(\n",
    "      [patch_size, patch_size, depth, depth], stddev=0.1))\n",
    "  layer2_biases = tf.Variable(tf.constant(1.0, shape=[depth]))\n",
    "  layer3_weights = tf.Variable(tf.truncated_normal(\n",
    "      [image_size // 4 * image_size // 4 * depth, num_hidden], stddev=0.1))\n",
    "  layer3_biases = tf.Variable(tf.constant(1.0, shape=[num_hidden]))\n",
    "    \n",
    "  number1_weights = tf.get_variable(\"WS1\", shape=[num_hidden, num_labels],\\\n",
    "           initializer=tf.contrib.layers.xavier_initializer())\n",
    "  number1_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "  number2_weights = tf.get_variable(\"WS2\", shape=[num_hidden, num_labels],\\\n",
    "           initializer=tf.contrib.layers.xavier_initializer())\n",
    "  number2_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "  number3_weights = tf.get_variable(\"WS3\", shape=[num_hidden, num_labels],\\\n",
    "           initializer=tf.contrib.layers.xavier_initializer())\n",
    "  number3_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "  number4_weights = tf.get_variable(\"WS4\", shape=[num_hidden, num_labels],\\\n",
    "           initializer=tf.contrib.layers.xavier_initializer())\n",
    "  number4_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "  number5_weights = tf.get_variable(\"WS5\", shape=[num_hidden, num_labels],\\\n",
    "           initializer=tf.contrib.layers.xavier_initializer())\n",
    "  number5_biases = tf.Variable(tf.constant(1.0, shape=[num_labels]))\n",
    "  \n",
    "  # Model.\n",
    "  def model(data):\n",
    "    #first convolutional layer\n",
    "    conv = tf.nn.conv2d(data, layer1_weights, [1, 2, 2, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + layer1_biases)\n",
    "    #second convolutional layer\n",
    "    conv = tf.nn.conv2d(hidden, layer2_weights, [1, 2, 2, 1], padding='SAME')\n",
    "    hidden = tf.nn.relu(conv + layer2_biases)\n",
    "    #fully-connected layer\n",
    "    shape = hidden.get_shape().as_list()\n",
    "    reshape = tf.reshape(hidden, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "    hidden = tf.nn.relu(tf.matmul(reshape, layer3_weights) + layer3_biases)\n",
    "    #layers for the 5 numbers and length\n",
    "    logits1 = tf.matmul(hidden, number1_weights) + number1_biases\n",
    "    logits2 = tf.matmul(hidden, number2_weights) + number2_biases\n",
    "    logits3 = tf.matmul(hidden, number3_weights) + number3_biases\n",
    "    logits4 = tf.matmul(hidden, number4_weights) + number4_biases\n",
    "    logits5 = tf.matmul(hidden, number5_weights) + number5_biases\n",
    "    return logits1, logits2, logits3, logits4, logits5\n",
    "  \n",
    "  # Training computation.\n",
    "  #print(logits1.shape)\n",
    "  #logits1, logits2, logits3, logits4, logits5, logits6 = model(tf_train_dataset)\n",
    "  logits1, logits2, logits3, logits4, logits5 = model(tf_train_dataset)\n",
    "  print(logits1) \n",
    "  print(tf_train_labels1)\n",
    "  #print(logits6)\n",
    "    \n",
    "  loss1 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits1, tf_train_labels1))\n",
    "  loss2 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits2, tf_train_labels2))\n",
    "  loss3 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits3, tf_train_labels3))\n",
    "  loss4 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits4, tf_train_labels4))\n",
    "  loss5 = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits5, tf_train_labels5))\n",
    "\n",
    "  loss = loss1 + loss2 + loss3 + loss4 + loss5\n",
    "  #loss = loss1\n",
    "\n",
    "  #loss = tf.add_n(loss_per_digit)\n",
    "\n",
    "  '''\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits1, tf_train_labels1) + \n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits2, tf_train_labels2) + \n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits3, tf_train_labels3) + \n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits4, tf_train_labels5) + \n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits5, tf_train_labels5) + \n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits6, tf_train_labels6))\n",
    "  '''\n",
    "  \n",
    "  # Optimizer.\n",
    "  # learning rate decay\n",
    "  #global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "  #learning_rate = tf.train.exponential_decay(0.5, global_step, 100, 0.96, staircase=True)\n",
    "  #optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    "\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.25).minimize(loss)\n",
    "\n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.concat(1, [tf.nn.softmax(logits1), tf.nn.softmax(logits2), tf.nn.softmax(logits3),\n",
    "                                  tf.nn.softmax(logits4), tf.nn.softmax(logits5)])\n",
    "  #train_prediction_6 = tf.nn.softmax(logits6)\n",
    "  \n",
    "  valid_logits1, valid_logits2, valid_logits3, valid_logits4, valid_logits5 = model(tf_valid_dataset)\n",
    "  test_logits1, test_logits2, test_logits3, test_logits4, test_logits5 = model(tf_test_dataset)\n",
    "    \n",
    "  valid_prediction = tf.concat(1, [tf.nn.softmax(valid_logits1), tf.nn.softmax(valid_logits2), \n",
    "                                                      tf.nn.softmax(valid_logits3),\n",
    "                                  tf.nn.softmax(valid_logits4), tf.nn.softmax(valid_logits5)])\n",
    "  \n",
    "  test_prediction = tf.concat(1, [tf.nn.softmax(test_logits1), tf.nn.softmax(test_logits2), tf.nn.softmax(test_logits3),\n",
    "                                  tf.nn.softmax(test_logits4), tf.nn.softmax(test_logits5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAKDUlEQVRIDR3BCXfaRgIA4JnRLQ6B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\nSUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAK+0lEQVRIDQXBV4yj+UEA8P//683l\ncx/3cZ9mT92Zvdvd3F7uKC8RPCHxElHCReQOQtERCQIECQVCBJwURTwQISEegAMeYBGXEHZXu9PH\nHns81TOebo89ruPy2Z+/yu8HP/rGZ31RYs0Gz7g3NT+RnPCSuA51VZe1w92TtVeZ82KpJ4z4MXds\nMuLxWxkWFUe9TqejKBKEOgS6pmmSouoAIwiGZYwUxZgMDEmiKKIrqgQ/+vivAU46vK5QPBSO+jhS\nxaFG4zhHc5eF27WXOxfnpaGk+ePRmaWp4LjFZCY0VekLg6EwkGVxJA4f2u3C2UWt9jAUNRRnzbxt\nzGk1mmiaRCFU4a9//D0DbwlEQ9HJqNVqHLSrGNDMHOdyjtVvm6svty+Kt6KqRVLTc49TXh9nMGIQ\n6LKkyKKkKtJwIFQq9+urW+eXpUZrKOukc8w9HnRbLAaGRqEuwV/55C8cbk9sKhGfjOGoViqe4VB3\n2qzh8VCvIay92j4/vxnKamxhZm4lZXMQDAMhABgACAAQgNFwVCnVfvI/Pz0uXJZrnaGKBcLhyUTI\nZjNQJFQkAX790791eD3xqXgsEUFUNbu+QWO43+NOxKMPrd7OWvb6qiSq6vhMLLWUtNkpmkYQCAgA\nEB0gOlBGaqcp/Me/vTg4LJYbHZWgHz97uvLOrN3KoYg86LfhVz/57ljAG5uMR+NhRFNOdvMUirqd\nrmgk1Gn3cjsHlWpTQ9HAVDiUCJmMFIEjUNcYDCURgAOgiEqjKnz+L/95cn7RHoqUxfrk/Wfvvjtt\ntdCaKrZqLfhLv/Yn7vFAfCIWiY3jUL8pFikUc9hsQb+v1XjY2z2pNzo6hnsiAbODxzEIdRWoGkfg\nZoZjCQoooHH/8OK/vritVmUM8h7X4y+tLMwHjRwhDgal6zv4C7/8LXcwEE1EI5EgQ+GdRo3CMQtv\ncjnslVItt1totgSEpFwBD0Ki4lAYDYe6orI46eDtPGsmINZuPrx5u9YVBcrMeqK++eWZWMRCIKDd\nfCienMOf/8XfG/P7wtFQKBLgeQ7TFZbCDRzDcezp8WVm56TTHZIM5wq4R5pyX610221FkkmEcFqd\nDpONwRmhNzg4PsEY3BV0RKZDiemAw4KPBOHu9u4gewSff/gNi8Pl9nsCIZ/P73JYWbOJY2kKhWBj\nPb21ftAXFKPFMh4bl9RRq3HfabeEXn80lBjSwBAGHNLSSOsII/e4azIVTi1EvAGShKBeqZ8dFTMb\nGfj06W8wJp532lweRyjsC4fGHA6epSlNkl++XE1vH6sqOubzpxanCRJR5dFQ6HUe2rV6s98RBx15\n0FOEoaLiTHQiNLsQm1sIeT0oroHyVekwd7SzloZPn3wNo1nayJlsplDEl0zGfD6nkWUkUXz5v29z\nu2coxoSi0ZWnSzyPYYiuSJLQH1TrjfJtrXRdK5ea9aagEFxsMjK/EF9cCIX9FKLoN8XL/Ux+Z3UH\nPn/2NR0jIYGTBtI37lleTkUiAStvlIbim/9b39+7IChDJB5/50srdjtGYgACoKmgPxAuLm6PDy+P\njq4ubmo9jQhFgnNzseWl6HTUgsjadaGYT2e3327Dn/vgIwUgEtB1DHH57EvLs9MzE163C9O0zbfp\nfK6o6cSY1z81N2UwUjiqURRqNNA8T1UqrYP8WTZ3eli4uW2O7GPOVDLy9PHk/IyP0vTr09Pc9u7m\nmy34q1/9FGCEBhEVaAqiJmanZ5JTkaCfp6mDzGE+d3l/3xVlQJrMAEdxAjqd5kQssDIXVCTt6qKc\nyxXebuytbhdtY67kXOzps+TzJ1OkCooHR+n1rY03W/Dbf/R9gmJUAERZ7g6FsbB/YnIiOh5wGg1n\n+2eZ7ZNisVJt9iSIKyjCGSm/35Wajv7Msxma0Cvl5n7+/NXr9Bev8iarLbkw8fzDhffenSBk/ezg\nKLO+vfFmG/7wh/9oMJk0CHsDodpsGlz2RDweCfqdBsNZ/nRjNX94dH1baQ10REag0cwFgu65VOwr\nHyxajHir3j06vH75aufFj3c53pxcmHz/Z5eePI6hI62YP0pvpDff7sDPP/9vm9Oho7Dd7V6Ubmne\nHItFQz6flaT3d/Krr3NHJ9d39Y6METLUGAPj9Tlnk9GvfPjIYeH67cFZofT6dfrFT7Isb5pZmHj+\n4eKjxRAykE/3jzPrma21DPzXf3/hCwYwHG91HwpXFzjHJmLxkNdnIojd1ezGWv7mpi6IKmE0SUBF\nCMRmN8XC3udPUjazUXgYXBbLa+u5H7/eN9ltM/OJp+/NzSbdamdU2DtKb6Z31nfhj/7pn/3BAEES\n3V7/9PqK4U3hcDjgcvMYkdva38uet1oCQEne5VARfaQMWZbw+5yP5icsJrbfHl6clt+uZb54vce7\n7LOLU+99eXEyYRfr3ZPcYXZrN721D3/wo39we30kRQrD4W2lwln5YCDgsTlYDc1u5k9P7xQVNVns\n/lBAgUq704Co6nJYktNRM0t1m4NiofRmNf3Fm5zN7VpcmXn/g6VoyNKrNE9yB9mt7G76EP7VD/7O\n4XKRNC0rSrPTNlh5n8drN/KYqKXXc9elFsWY/cFQfComa2K1VpLloYXnYpEgRxKdev+scPtmNfPT\nzf0xv/fR49T7X14c9xvbt9Xj7H52J5fLHMPvfO8zi9VKswyCoZImG8wmp91hIFm1O9pczd7VB2bb\nWCwRn0xGJVloNO6kUZ9hCJ/HRSFku9YtFm7WNvMb+8XxaOjR4+STp8mAm2tc3h5m97Pp/F72BP7u\nt//caDIbTUaDwUCxpN1pZylGH+kP1d7m5l6pMTRY7KFYODkbB2AwHDzoikiRiNNqwQHeqvUuTstb\nmcPcWTk2nVhemXm8HPe52Or51WFuP7uzt5c7hr/5+39M0pTRZOR5i8XC2x0WFKD9h0H5oraxfVDt\nqAa7I5yIzC1MGDioSj0UyByNOXleHip3V43CyU02f3bdHCRmEssrUytLEY+NrlxcH+cPc5l8JnMA\nP/mD7wAUZRjGbDJZrRaOIVVZ7TYHpev6dva0JuiczRGKh+YXE26nAUdkEtNZErOwTLvevTwrnx7f\nFIrlHqSmZieXluILqYDbSt5flQoHhdzu/tZ2Dn7rz76vaDqGYTRNm40GZSSOxFG/IzZrg/zJTW2o\n0bzFN+5LzkajQaeZJVgKoVCEhPD2qlI8uSkWy3e1Dml3pxam5+ci03Gn04y3yrXzk/Nc9mB9PQ3/\n8rO/V1QFQIhhGMMwA0Hod4ReTxR68mW5WRdkhKYsNnMoOJYIey1GhiVwHEJd1oqFy0Lh6rZcEwES\nTCVT81PJ6fF40GomwKDZK12Vjw4LW9tZ+Kff/RtFUwFAMBxnGMZkMA0EURBESdI6gvIgKgqAGIGa\nDLjNzFEQojqEGtAVcHV5c3VzV3/oYhw7/c7y5EwsHvYFXWYWKqPu4L5cPSucZ3KH8Juf/qGiqgAA\nBMMomrZZHbKiKZIKdIgQjAxwDSIQARQOcBRCWdMkRZEUVQblu0r5/r7d7xMcG380F44Ggh6nhzca\ncARKaqNavzi/zh8W4Nc//i1FVTQdICiCUxTHmQBAAIAoRI1GC0KwCIqjGEIRiCxLuqTJI0UaSqoK\nGq1246HVGw5QmvBPRcfGnA6LycrSZpIidKRZb95cl8/Or+Bv/843FU3RdA0iCEqQQ1ECACIQRSDK\nsSYMY3CCIinKYKQkSUIAqqtQlhQEwYeiKIiDoSSqCLB4nQYDRxMYCYGRoHGAtOrtaqVWva//P7hL\nbe0m2WezAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch loss at step 0: 38.804531\n",
      "[  1.27770077e-03   1.84301231e-02   1.04212944e-04   1.93118581e-06\n",
      "   6.69066980e-09   1.82654869e-04   1.68154045e-04   7.90327549e-01\n",
      "   3.99124809e-03   1.84730604e-01   7.85875425e-04]\n",
      "[ 0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]\n",
      "Predicted: 7 9 7 7 7\n",
      "Actual: 3 5 1 10 10\n",
      "Minibatch accuracy: 0.0%\n",
      "[ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]"
     ]
    }
   ],
   "source": [
    "#batch_size = 100\n",
    "num_steps = 100000\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print('Initialized')\n",
    "  for step in range(num_steps):\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :, :, :]\n",
    "\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    batch_labels1 = train_labels_1[offset:(offset + batch_size), :]\n",
    "    batch_labels2 = train_labels_2[offset:(offset + batch_size), :]\n",
    "    batch_labels3 = train_labels_3[offset:(offset + batch_size), :]\n",
    "    batch_labels4 = train_labels_4[offset:(offset + batch_size), :]\n",
    "    batch_labels5 = train_labels_5[offset:(offset + batch_size), :]\n",
    "    \n",
    "    batch_image_labels = train_image_labels[offset:(offset + batch_size)]\n",
    "    \n",
    "\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels1 : batch_labels1, tf_train_labels2 : batch_labels2\n",
    "                , tf_train_labels3 : batch_labels3, tf_train_labels4 : batch_labels4, tf_train_labels5 : batch_labels5}\n",
    "    \n",
    "    _, l, l1, l2, l3, l4, l5, predictions = session.run(\n",
    "      [optimizer, loss, loss1, loss2, loss3, loss4, loss5, train_prediction], feed_dict=feed_dict)\n",
    "    #print(train_prediction)\n",
    "    #print(batch_labels1)\n",
    "    #print(predictions)\n",
    "    if (step % 500 == 0):\n",
    "      try:\n",
    "          display(Image(filename=\"train/cropped/\" + str(batch_image_labels[0]) + \".png\"))\n",
    "      except IOError as e:\n",
    "          print('')\n",
    "      try:\n",
    "          display(Image(filename=\"test/cropped/\" + str(batch_image_labels[0]) + \".png\"))\n",
    "      except IOError as e:\n",
    "          print('')\n",
    "      #print(batch_labels[1].reshape(5,11))\n",
    "      print('Minibatch loss at step %d: %f' % (step, l))\n",
    "      #print(batch_labels.shape)\n",
    "      print('Minibatch accuracy: %.1f%%' % accuracy(predictions, batch_labels))\n",
    "      print('Validation accuracy: %.1f%%' % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print('Test accuracy: %.1f%%' % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
